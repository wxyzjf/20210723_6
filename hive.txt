hive> CREATE TABLE pokes (foo INT, bar STRING);

CREATE TABLE test_e (num INT, str_a STRING,str_b STRING,str_c STRING,info INT);
LOAD DATA INPATH '/test/test.csv' OVERWRITE INTO TABLE test_e;

hive> CREATE TABLE invites (foo INT, bar STRING) PARTITIONED BY (ds STRING);



hive> show create table h_fw_cdr;
OK
CREATE TABLE `h_fw_cdr`(
  `batch_no` string, 
  `start_datetime` string, 
  `src` string, 
  `json_value` string)
PARTITIONED BY ( 
  `start_date` string)
ROW FORMAT SERDE 
  'org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe' 
WITH SERDEPROPERTIES ( 
  'field.delim'='|', 
  'serialization.format'='|') 
STORED AS INPUTFORMAT 
  'org.apache.hadoop.mapred.TextInputFormat' 
OUTPUTFORMAT 
  'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
LOCATION
  'maprfs:/HDS_VOL_HIVE/FWCDR'
TBLPROPERTIES (
  'transient_lastDdlTime'='1565257228')
Time taken: 0.034 seconds, Fetched: 20 row(s)


 hive> SHOW TABLES;


  hive> SHOW TABLES '.*s';

hive> DESCRIBE invites;
       
  hive> ALTER TABLE events RENAME TO 3koobecaf;
  hive> ALTER TABLE pokes ADD COLUMNS (new_col INT);
  hive> ALTER TABLE invites ADD COLUMNS (new_col2 INT COMMENT 'a comment');
  hive> ALTER TABLE invites REPLACE COLUMNS (foo INT, bar STRING, baz INT COMMENT 'baz replaces new_col2');
  hive> ALTER TABLE invites REPLACE COLUMNS (foo INT COMMENT 'only keep the first column');


hive> DROP TABLE pokes;
hive> LOAD DATA LOCAL INPATH './examples/files/kv1.txt' OVERWRITE INTO TABLE pokes;

  hive> LOAD DATA LOCAL INPATH './examples/files/kv2.txt' OVERWRITE INTO TABLE invites PARTITION (ds='2008-08-15');
  hive> LOAD DATA LOCAL INPATH './examples/files/kv3.txt' OVERWRITE INTO TABLE invites PARTITION (ds='2008-08-08');


alter table h_cf_cdr add if not exists partition (part_key='20200508') LOCATION '/HDS_VOL_HIVE/cf/part_key=20200508'; 
load data LOCAL inpath '/app/HDSBAT/cvtdata/CF_CDR/CF_20200508_20200509100112_01_proc_1.gz' into table h_cf_cdr partition(part_key='20200508');


 hive> LOAD DATA INPATH '/user/myname/kv2.txt' OVERWRITE INTO TABLE invites PARTITION (ds='2008-08-15');



 hive> SELECT a.foo FROM invites a WHERE a.ds='2008-08-15';

hive> INSERT OVERWRITE DIRECTORY '/tmp/hdfs_out' SELECT a.* FROM invites a WHERE a.ds='2008-08-15';

Note that in all the examples that follow, INSERT (into a Hive table, local directory or HDFS directory) is optional.
 hive> INSERT OVERWRITE DIRECTORY '/tmp/hdfs_out' SELECT a.* FROM invites a WHERE a.ds='2008-08-15';

hive> INSERT OVERWRITE LOCAL DIRECTORY '/tmp/local_out' SELECT a.* FROM pokes a;


  hive> INSERT OVERWRITE TABLE events SELECT a.* FROM profiles a;
  hive> INSERT OVERWRITE TABLE events SELECT a.* FROM profiles a WHERE a.key < 100;
  hive> INSERT OVERWRITE LOCAL DIRECTORY '/tmp/reg_3' SELECT a.* FROM events a;
  hive> INSERT OVERWRITE DIRECTORY '/tmp/reg_4' select a.invites, a.pokes FROM profiles a;
  hive> INSERT OVERWRITE DIRECTORY '/tmp/reg_5' SELECT COUNT(*) FROM invites a WHERE a.ds='2008-08-15';
  hive> INSERT OVERWRITE DIRECTORY '/tmp/reg_5' SELECT a.foo, a.bar FROM invites a;
  hive> INSERT OVERWRITE LOCAL DIRECTORY '/tmp/sum' SELECT SUM(a.pc) FROM pc1 a;

  hive> FROM invites a INSERT OVERWRITE TABLE events SELECT a.bar, count(*) WHERE a.foo > 0 GROUP BY a.bar;
  hive> INSERT OVERWRITE TABLE events SELECT a.bar, count(*) FROM invites a WHERE a.foo > 0 GROUP BY a.bar;


  hive> FROM pokes t1 JOIN invites t2 ON (t1.bar = t2.bar) INSERT OVERWRITE TABLE events SELECT t1.bar, t1.foo, t2.foo;


  FROM src
  INSERT OVERWRITE TABLE dest1 SELECT src.* WHERE src.key < 100
  INSERT OVERWRITE TABLE dest2 SELECT src.key, src.value WHERE src.key >= 100 and src.key < 200
  INSERT OVERWRITE TABLE dest3 PARTITION(ds='2008-04-08', hr='12') SELECT src.key WHERE src.key >= 200 and src.key < 300
  INSERT OVERWRITE LOCAL DIRECTORY '/tmp/dest4.out' SELECT src.value WHERE src.key >= 300;

  hive> FROM invites a INSERT OVERWRITE TABLE events SELECT TRANSFORM(a.foo, a.bar) AS (oof, rab) USING '/bin/cat' WHERE a.ds > '2008-08-09';



CREATE TABLE u_data (
  userid INT,
  movieid INT,
  rating INT,
  unixtime STRING)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY '\t'
STORED AS TEXTFILE;



LOAD DATA LOCAL INPATH '<path>/u.data'
OVERWRITE INTO TABLE u_data;

SELECT COUNT(*) FROM u_data;

import sys
import datetime

for line in sys.stdin:
  line = line.strip()
  userid, movieid, rating, unixtime = line.split('\t')
  weekday = datetime.datetime.fromtimestamp(float(unixtime)).isoweekday()
  print '\t'.join([userid, movieid, rating, str(weekday)])


CREATE TABLE u_data_new (
  userid INT,
  movieid INT,
  rating INT,
  weekday INT)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY '\t';

 
CREATE TABLE test_e (
num int,
str_a string,
str_b string ,
str_c string,
info  int)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ',';

add FILE weekday_mapper.py;

INSERT OVERWRITE TABLE u_data_new
SELECT
  TRANSFORM (userid, movieid, rating, unixtime)
  USING 'python weekday_mapper.py'
  AS (userid, movieid, rating, weekday)
FROM u_data;

SELECT weekday, COUNT(*)
FROM u_data_new
GROUP BY weekday;
 



 






---------------------------------------------------------------------------


--alter table invites add if not exists partition (ds='2008-08-16');
LOAD DATA LOCAL INPATH '/tmp/test/kv3.txt' INTO TABLE invites PARTITION (ds='2008-08-17');
or LOAD DATA LOCAL INPATH '/tmp/test/part_key=$part_time' INTO TABLE invites PARTITION (ds='2008-08-17');


hadoop fs -copyFromLocal /tmp/test/kv2.txt /user/hive/warehouse/invites part_key=$part_time
or hadoop fs -copyFromLocal /tmp/test/kv2.txt /user/hive/warehouse/invites/part_key=$part_time



CREATE TABLE invites (
  foo INT,
  bar STRING)
PARTITIONED BY (ds STRING)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY '|'
STORED AS TEXTFILE
LOCATION '/tmp/test';

hive> show create table invites;
OK
hive> CREATE TABLE invites (
    >   foo INT,
    >   bar STRING)
    > PARTITIONED BY (ds STRING)
    > ROW FORMAT DELIMITED
    > FIELDS TERMINATED BY '|'
    > STORED AS TEXTFILE
    > LOCATION '/tmp/test';
OK
Time taken: 0.051 seconds
hive> show CREATE TABLE invites;
OK
CREATE TABLE `invites`(
  `foo` int, 
  `bar` string)
PARTITIONED BY ( 
  `ds` string)
ROW FORMAT SERDE 
  'org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe' 
WITH SERDEPROPERTIES ( 
  'field.delim'='|', 
  'serialization.format'='|') 
STORED AS INPUTFORMAT 
  'org.apache.hadoop.mapred.TextInputFormat' 
OUTPUTFORMAT 
  'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
LOCATION
  'maprfs:/tmp/test'
TBLPROPERTIES (
  'transient_lastDdlTime'='1589010040')
Time taken: 0.046 seconds, Fetched: 18 row(s)






















https://cwiki.apache.org/confluence/display/Hive/GettingStarted
https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL
https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DML
https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Select
http://www.hplsql.org/doc
